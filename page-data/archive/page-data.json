{"componentChunkName":"component---src-pages-archive-js","path":"/archive/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"frontmatter":{"date":"2021-01-01","title":"FAQ Generation and Querying using Transformers","tech":["Python","Tensorflow","transformers","HuggingFace","ntlk"],"github":null,"external":null,"company":"Princeton University"},"html":"<p>Utilized a BERT-based transformer model to generate a FAQ list given a product description table. Implemented efficient information retrieval by comparing sentence embeddings of user input with questions.</p>\n<p>Note: The data is not open, so I am unable to share the code. I am happy, however, to share any insights from this.</p>"}},{"node":{"frontmatter":{"date":"2020-06-01","title":"Cross-Domain Few-Shot Learning","tech":["Python","PyTorch","Torchvision","Computer Vision"],"github":"https://github.com/johncai117/Meta-Fine-Tuning","external":"https://arxiv.org/abs/2005.10544","company":"Princeton University"},"html":""}},{"node":{"frontmatter":{"date":"2020-06-01","title":"Neural Machine Translation","tech":["Python","PyTorch","NLTK","Natural Language Processing"],"github":"https://github.com/johncai117/neural-machine-translation","external":null,"company":"Princeton University"},"html":"<p>Implemented a neural machine translator using an encoder-decoder network with multiplicative attention. The project translates English to French, and investigates the effects of different types of attention on performance.</p>"}},{"node":{"frontmatter":{"date":"2020-06-01","title":"Zero-shot Recognition","tech":["Python","PyTorch","OpenCV","Seaborn"],"github":"","external":"https://www.academia.edu/44235068/Zero_Shot_Recognition_with_Attributes","company":"Princeton University"},"html":"<p>Zero-shot learning involves making a neural network that can recognize images from classes that were never seen before. Applied SIFT and ResNet101 for feature extraction and applied a relation network to combine the attribute vector with the image feature vector. Achived a significant increase in accuracy with ResNet101 + Relation Network.</p>"}},{"node":{"frontmatter":{"date":"2020-05-01","title":"Visual Question Answering","tech":["Python","PyTorch","FastText","Computer Vision","Natural Language Processing"],"github":"https://github.com/johncai117/VQA-Project","external":"https://www.academia.edu/44232933/Visual_Question_Answering_using_LSTM_and_ResNet","company":"Princeton University"},"html":"<p>Used a pre-trained FastText model to extract word embeddings from the questions followed by a bi-directional LSTM to convert the sentences into sentence vectors. Applied a ResNet101 model to extract image features, and combined the image and sentence vectors into another neural network.</p>"}},{"node":{"frontmatter":{"date":"2020-05-01","title":"Bundle Adjustment for 3D Computer Vision","tech":["Python","Numpy","3D Vision"],"github":"https://github.com/johncai117/bundle-adjust","external":null,"company":"Princeton University"},"html":"<p>A more math-heavy project. Bundle adjustment takes a set of parameters to minimize reprojection error of multiple cameras. For efficient code implementation, I utilized a modified Levenberg-Marquardt algorithm and exploited the sparse structure of the matrices.</p>"}},{"node":{"frontmatter":{"date":"2020-03-02","title":"CycleGAN for Style Transfer","tech":["Python","TensorFlow","GANs","Computer Vision"],"github":"https://github.com/johncai117/Generative-Adversarial-Network","external":null,"company":"Princeton University"},"html":"<p>Utilized a Cycle-Consistent Generative Adversarial Networks for style transfer. This project aims to generate Monet-like paintings from natural images.</p>"}},{"node":{"frontmatter":{"date":"2020-03-01","title":"House Price Prediction using XGBoost","tech":["Python","XGBoost","Sci-kit Learn"],"github":null,"external":null,"company":"Princeton University"},"html":"<p>Cleaned and processed a dataset and applied XGBoost to achieve highger accuracies. Interpolated missing data using K-Nearest-Neighbors.</p>"}},{"node":{"frontmatter":{"date":"2020-03-01","title":"Probabilistic Graphical Inference","tech":["Python","Numpy","Markov Random Fields","Bayesian Statistics"],"github":"https://github.com/johncai117/Probabilistic-Graphical-Inference","external":null,"company":"Princeton University"},"html":"<p>A more math-heavy project. Probabilistic Graphical Models are commonly used to represent rich joint distributions of different variables, and has many applications in modern deep learning. Developed efficient implementation of Belief Propagation on Markov Random Fields to estimate marginal and joint probabilities and for MAP estimates.</p>"}},{"node":{"frontmatter":{"date":"2020-01-02","title":"Engineering Barrier Options in C++","tech":["C++","Armadillo","XLW","Financial Engineering"],"github":"https://github.com/johncai117/Pricing-Barrier-Options","external":"https://www.academia.edu/44228698/Pricing_barrier_options_using_PDEs_in_C_","company":"Princeton University"},"html":"<p>Simulated barrier option prices using Markov Chain Monte Carlo (MCMC) and Partial Differential Equation (PDE) methods in C++.</p>"}},{"node":{"frontmatter":{"date":"2020-01-01","title":"Event-driven Stock Price Prediction","tech":["Python","PyTorch","FastText","OpenIE","NLTK","Natural Language Processing"],"github":null,"external":"https://www.academia.edu/42103229/Event_driven_Stock_Price_Prediction_using_Convolutional_Neural_Networks_for_Natural_Language_Processing","company":"Princeton University"},"html":"<p>Predicted stock prices using a convolutional neural net operating across the temporal dimension.</p>"}},{"node":{"frontmatter":{"date":"2020-01-01","title":"Named Entity Recognition","tech":["Python","PyTorch","scikit-learn","Natural Language Processing"],"github":"https://github.com/johncai117/named-entity-recognition","external":null,"company":"Princeton University"},"html":"<p>Implemented a named entity recognition system using Hidden Markov Models Viterbi decoding and a Feedforward Neural Network. Compared the two and found that HMM Viterbi decoding worked better.</p>"}},{"node":{"frontmatter":{"date":"2019-06-01","title":"Predicting Economic Recessions using NLP","tech":["Python","MATLAB","BeautifulSoup","Selenium","NLTK","scikit-learn"],"github":"","external":"https://www.academia.edu/40813014/Predicting_Economic_Recessions_using_Natural_Language_Processing","company":"University of Cambridge"},"html":"<p>Dissertation at Cambridge. Used NLP to study if economic uncertainty can predict recessions. Implemented web-scrapers to retrieve over 300,000 news articles using Selenium/ BeautifulSoup. Quantified economic uncertainty using MaxEnt models. Invited to publish.</p>"}},{"node":{"frontmatter":{"date":"2018-06-01","title":"Principal Factors behind Measured Gains in Education","tech":["Stata","Econometrics","Causal Inference"],"github":"","external":"https://www.academia.edu/37800063/Principal_factors_behind_measured_gains_in_education_a_natural_experiment_approach","company":"University of Cambridge"},"html":"<p>Investigated the principal factors behind measured gains in education by exploiting a natural experiment in schooling age. Performed causal inference using instrumental variables and estimated the extra value of a day in school on education outcomes.</p>"}}]}},"pageContext":{}},"staticQueryHashes":["1994492073","3391063840","3618961439","4112399270","604461682"]}